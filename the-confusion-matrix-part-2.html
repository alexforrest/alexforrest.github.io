<!DOCTYPE html>
<html lang="en">
<head>
        <title>The Confusion Matrix: Part 2</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css" />
        <link rel="stylesheet" href="./theme/css/main.css" />
</head>
<body>

    <div class="main-nav-container">

        <div class="pure-g">
            <div class="pure-u-1 pure-u-lg-2-3">
                <div class="main-nav">
                    <ul class="main-nav-list">
                        <li class="main-nav-item"><a href="./" class="pure-menu-link">Alex Harlan</a></li>

                        <li class="main-nav-item active"><a href="./category/blog.html" class="pure-menu-link">Blog</a></li>
                        <li class="main-nav-item"><a href="./category/projects.html" class="pure-menu-link">Projects</a></li>
                    </ul>
                </div>
             </div>

             <div class="pure-u-1 pure-u-lg-1-3"></div>
        </div>

    </div>


<div class="page-container">
    <div class="entry-content">
        <div class="post-meta pure-g">
            <div class="pure-u-3-4 meta-data">
                <a href="./category/blog.html" class="category">Blog</a><br />

                <a class="author" href="./author/alex-harlan.html">Alex Harlan</a>
                &mdash; <abbr title="2018-05-10T00:00:00-07:00">Thu 10 May 2018</abbr>
            </div>
        </div>
    </div>

    <div class="article-header-container">
        <div class="background-image-container">

            <div class="background-image-small">
                
                <div class="title-container">
                    <h1>The Confusion Matrix: Part 2</h1>
                    <h4>Precison and Recall</h4>
                </div>
            </div>
        </div>
    </div>

    <div class="entry-content">
        <article class="h-entry">

<section data-field="body" class="e-content">
<section name="bc05" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="ec2a" id="ec2a" class="graf graf--h3 graf--leading graf--title"></h3><h3 name="0e15" id="0e15" class="graf graf--h3 graf-after--h3"></h3><p name="378f" id="378f" class="graf graf--p graf-after--h3">As a reminder, confusion matrices are used in classification problems to help us understand how our models are performing. Let’s start by recalling the confusion matrix for a binary classification problem. </p><figure name="b3e8" id="b3e8" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder"><img class="graf-image" data-image-id="1*aO30Iz8JLi7rCs7nbs__Qg.png" src="https://cdn-images-1.medium.com/max/800/1*aO30Iz8JLi7rCs7nbs__Qg.png"></div></figure><p name="7c9a" id="7c9a" class="graf graf--p graf-after--figure">Using the confusion matrix we can describe two new concepts, precision and recall. </p><p name="a0a4" id="a0a4" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Precision </strong>is the fraction of positive predictions that were actually positive. </p><p name="6091" id="6091" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Recall</strong> is the fraction of positive data that is predicted to be positive. </p><p name="547c" id="547c" class="graf graf--p graf-after--p">This might be a bit abstract without an example so let's use an example to understand how these concepts are helpful in examining our classification models. </p><p name="2023" id="2023" class="graf graf--p graf-after--p"> Once again, suppose we are looking to predict individuals who have some rare disease and those who don't. Most of our samples are individuals who do not have the disease, and we get the following confusion matrix after fitting our model. </p><figure name="f0af" id="f0af" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 471px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 4%;"></div><img class="graf-image" data-image-id="1*LrBSNufLn_XR7MSQ398H8w.png" data-width="730" data-height="491" src="https://cdn-images-1.medium.com/max/800/1*LrBSNufLn_XR7MSQ398H8w.png"></div></figure><p name="4205" id="4205" class="graf graf--p graf-after--figure"> How many data points do we have? 10+15+35+1000 = 1060</p><p name="671d" id="671d" class="graf graf--p graf-after--p">How many are false positives? Our false positives are the samples that were predicted to be positive(1) but are actually negative(0), this corresponds to the bottom left matrix entry, so 15. </p><p name="839c" id="839c" class="graf graf--p graf-after--p graf--trailing">Okay we know how our confusion matrix works, now how do we make sense of precision and recall?</p></div></div></section><section name="3eb1" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="076c" id="076c" class="graf graf--p graf--leading">We know that <strong class="markup--strong markup--p-strong">precision</strong> is the fraction of positive predictions that were actually positive. So we just need to find the number of positive prediction that were actually positive and the total number of positive predictions. </p><p name="2ff2" id="2ff2" class="graf graf--p graf-after--p">The number of positive predictions that were actually positive is simply the number of true positives (TP). Next we look to find all the positive predictions, which we find corresponds with the first column of confusion matrix or the true positives (TP) and false positives (FP), so our total number of positive predictions is TP + FP.</p><p name="50cd" id="50cd" class="graf graf--p graf-after--p">Putting it all together our <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">formula for precision</em></strong> is TP/(TP+FP). </p><p name="1241" id="1241" class="graf graf--p graf-after--p">For our above example we get precision 10/25 or 40%. </p><p name="4683" id="4683" class="graf graf--p graf-after--p graf--trailing">What this means is that we have predicted 25 people to have the disease but we were only right 40% of the time. That’s less than half of the time that we were right.</p></div></div></section><section name="5131" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="39b1" id="39b1" class="graf graf--p graf--leading">We also know that <strong class="markup--strong markup--p-strong">recall</strong> is  the fraction of positive data that is predicted to be positive. We need to find the number of positive data in our data set and the number of positive predictions that were actually positive. We already found the total number of positive predictions that were actually positive TP. Therefore we only need to find the number of positive data in our set. This corresponds to the first row of our confusion matrix. Our first row contains true positives and false negatives (FN). </p><p name="a324" id="a324" class="graf graf--p graf-after--p">So our <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">formula for recall</em></strong> is TP/(TP+FN).</p><p name="04fe" id="04fe" class="graf graf--p graf-after--p">Going back to our example our recall is 10/45 or roughly 22%. </p><p name="387f" id="387f" class="graf graf--p graf-after--p graf--trailing">This means that 45 people actually had the disease and we only correctly identified 22% of them.</p></div></div></section><section name="0eeb" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="85ec" id="85ec" class="graf graf--p graf--leading">As you can see precision and recall helps us summarize the performance of our model in a more precise way. Our precision and recall will always fall on the interval [0, 1] with 0 being the worst case and 1 being the best. </p><p name="9893" id="9893" class="graf graf--p graf-after--p">We can also plot precision and recall on a precision recall curve. When we do we see that there is a tradeoff between precision and recall. The higher your precision the lower your recall and vice versa. In real life these plots might cross over once or multiple times.</p><figure name="467f" id="467f" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 509px; max-height: 351px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 1%;"></div><img class="graf-image" data-image-id="1*GrzktUSqROK7eBeqRsZkvg.png" data-width="509" data-height="351" src="https://cdn-images-1.medium.com/max/800/1*GrzktUSqROK7eBeqRsZkvg.png"></div></figure><p name="4709" id="4709" class="graf graf--p graf-after--figure">The amount of trade off you are willing to endure depends on what type of problem you are trying to solve. For instance if we are trying to classify cars coming off an assembly line as ‘ready for shipment’ (1) or ‘defective’ (0), we might be tempted to maximize precision as it will allow us to ship the most cars and thus maximize profits. However shipping defective cars can be extremely risky and cost car manufacturers hundreds of millions of dollars in lawsuits and on lost product, not to mention any costs associated with negative image. In this case we’d probably want to maximize recall at the expense of precision. It would be better to give cars that should have been marked ‘ready for shipment’ a second look over, than risk shipping defective product.</p><blockquote name="64bf" id="64bf" class="graf graf--blockquote graf-after--p">This may not be exactly what car manufactures do to prevent shipping defective product, but it is how they think about these kinds of trade offs. A lot of money and effort is put into preventive measures because of the high cost of mistakes.</blockquote><p name="705a" id="705a" class="graf graf--p graf-after--blockquote">You should be thinking carefully about what kind of error you are willing to accept. Understanding confusion matrices will help you do this.</div></div></section>
</section>
</article>
    </div>

    <footer>
        <div class="tags">
            <a href="./tag/confusion-matrix.html">confusion matrix</a>
            <a href="./tag/classification.html">classification</a>
            <a href="./tag/precision.html">precision</a>
            <a href="./tag/recall.html">recall</a>
        </div>
        <div class="pure-g post-footer">
            <div class="pure-u-1 pure-u-md-1-2">
                <div class="pure-g poster-info">
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./author/alex-harlan.html">Alex Harlan</a></h3>
                        <p class="author-description">
                        </p>
                    </div>
                </div>
            </div>



        </div>


    </footer>


</div>


</body>
</html>