<!DOCTYPE html>
<html lang="en">
<head>
        <title>Ridge and Lasso</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css" />
        <link rel="stylesheet" href="./theme/css/main.css" />
</head>
<body>

    <div class="main-nav-container">

        <div class="pure-g">
            <div class="pure-u-1 pure-u-lg-2-3">
                <div class="main-nav">
                    <ul class="main-nav-list">
                        <li class="main-nav-item"><a href="./" class="pure-menu-link">Alex Harlan</a></li>

                        <li class="main-nav-item active"><a href="./category/blog.html" class="pure-menu-link">Blog</a></li>
                        <li class="main-nav-item"><a href="./category/projects.html" class="pure-menu-link">Projects</a></li>
                    </ul>
                </div>
             </div>

             <div class="pure-u-1 pure-u-lg-1-3"></div>
        </div>

    </div>


<div class="page-container">
    <div class="entry-content">
        <div class="post-meta pure-g">
            <div class="pure-u-3-4 meta-data">
                <a href="./category/blog.html" class="category">Blog</a><br />

                <a class="author" href="./author/alex-harlan.html">Alex Harlan</a>
                &mdash; <abbr title="2018-06-03T00:00:00-07:00">Sun 03 June 2018</abbr>
            </div>
        </div>
    </div>

    <div class="article-header-container">
        <div class="background-image-container">

            <div class="background-image-small">
                
                <div class="title-container">
                    <h1>Ridge and Lasso</h1>
                    <h4>Knowing the Difference</h4>
                </div>
            </div>
        </div>
    </div>

    <div class="entry-content">
        <article class="h-entry">

<section data-field="body" class="e-content">
<section name="93ce" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="d91f" id="d91f" class="graf graf--h3 graf--leading graf--title"></h3><p name="98a0" id="98a0" class="graf graf--p graf-after--h3">Recently, I read an article where a current data scientist discussed her struggles to remember the difference between ridge and lasso regression.The goal of this post is to help those of you who are new to data science and are similarly struggling, hopefully get a better idea ridge and lasso regression.</p><h4 name="a820" id="a820" class="graf graf--h4 graf-after--p"><b>Start With What You Know</b></h4><p name="aeb5" id="aeb5" class="graf graf--p graf-after--h4">Both ridge and lasso regression are ‘modifications’ of ordinary least squares linear regression. In OLS multiple linear regression our cost function is:</p><figure name="22c0" id="22c0" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 105px; max-height: 56px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 4%;"></div><img class="graf-image" data-image-id="1*p-KSsFuCX6nbPvH_HD5A3w.png" data-width="105" data-height="56" src="https://cdn-images-1.medium.com/max/800/1*p-KSsFuCX6nbPvH_HD5A3w.png"></div></figure><p name="4965" id="4965" class="graf graf--p graf-after--figure">Here n is the number of data points or samples, <strong class="markup--strong markup--p-strong">y</strong> is our target vector, <strong class="markup--strong markup--p-strong">X</strong> is the input matrix, and β is our coefficients vector.</p><h4 name="498c" id="498c" class="graf graf--h4 graf-after--p"><b>Question What You Know</b></h4><p name="0b54" id="0b54" class="graf graf--p graf-after--h4">OLS linear regression is a useful technique but its not always the ideal method. For instance, what about if we have outliers? Or how might multicollinearity affect our model? When asking questions like these it becomes clear that OLS is not always the idea method for regression.</p><p name="8876" id="8876" class="graf graf--p graf-after--p">Let’s say we want to run a linear regression on features that exhibit multicollinearity. Multicollinearity can cause our variance to be high, which will result in overfitting our model. Since we want our models to generalize to new data, it is helpful to have a method for preventing this kind of overfitting.</p><p name="fe71" id="fe71" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Regularization </strong>is a means to avoid high variance in our model. To do this we will introduce a <strong class="markup--strong markup--p-strong">penalty term</strong> to the cost function above. By adding this penalty term we will prevent the coefficients of the linear function from getting too large. Introducing this bias should decrease the variance and thus prevent overfitting.</p><h4 name="6b39" id="6b39" class="graf graf--h4 graf-after--p"><b>The Ridge Cost Function</b></h4><p name="20e5" id="20e5" class="graf graf--p graf-after--h4">The ridge cost function adds the L2 norm of β as its penalty term, which is just a fancy way of saying we’re ‘adding all the coefficients squared’. This is not quite right because we want to have some control over how much the L2 norm of β will affect our model, so we multiple by a tuning parameter, λ.</p><figure name="9bb5" id="9bb5" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 197px; max-height: 63px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 4%;"></div><img class="graf-image" data-image-id="1*h0-7m3ONrknVPcmln9YkOw.png" data-width="197" data-height="63" src="https://cdn-images-1.medium.com/max/800/1*h0-7m3ONrknVPcmln9YkOw.png"></div></figure><p name="05a7" id="05a7" class="graf graf--p graf--empty graf-after--figure"><br></p><p name="1de9" id="1de9" class="graf graf--p graf-after--p">When λ is significantly large the sum of squared errors term in our cost function becomes insignificant. Since we are looking to minimize the above function, this forces β to 0. So we see that as λ increases, the values in β decrease. This is the behavior we wanted, because it reduces the variance. You can just think about calculating the variance with smaller coefficients to see why this is the case.</p><h4 name="d3b4" id="d3b4" class="graf graf--h4 graf-after--p"><b>The Lasso Cost Function</b></h4><p name="4881" id="4881" class="graf graf--p graf-after--h4">The lasso cost function on the other hand uses the L1 norm of β as its penalty term. The L1 norm of β is the sum of the absolute values of our coefficients.</p><figure name="215e" id="215e" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 211px; max-height: 60px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 4%;"></div><img class="graf-image" data-image-id="1*LmsyiapEH15OYzccdrjVgg.png" data-width="211" data-height="60" src="https://cdn-images-1.medium.com/max/800/1*LmsyiapEH15OYzccdrjVgg.png"></div></figure><p name="2d99" id="2d99" class="graf graf--p graf-after--figure">Similarly as λ gets significantly large β is forced to 0. But what is important to note about the lasso cost function, is that because we are using the absolute value, instead of the square of our coefficients, less important features’ coefficients can be assigned a value of 0. This is particularly helpful for feature selection.</p><p name="54f5" id="54f5" class="graf graf--p graf-after--p">The reason why the penalty term results in coefficients being zero has to do with the constraint region, which I won’t go into here, but I recommend reading into because it will be helpful in order to cement the idea that the L1 penalty allows for some coefficients to be zero.</p><figure name="313f" id="313f" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 427px; max-height: 240px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 4%;"></div><img class="graf-image" data-image-id="1*UiLesmZjRH6xY1V6UMFClw.png" data-width="427" data-height="240" src="https://cdn-images-1.medium.com/max/800/1*UiLesmZjRH6xY1V6UMFClw.png"></div><figcaption class="imageCaption">Lasso constraint region in blue (left), Ridge (right)</figcaption></figure><h4 name="a484" id="a484" class="graf graf--h4 graf-after--figure"><b>Putting it Together</b></h4><p name="25c6" id="25c6" class="graf graf--p graf-after--h4">Once we understand what ridge and lasso regression are doing, it is easier to remember which uses which regularization method.</p><p name="f31c" id="f31c" class="graf graf--p graf-after--p">Personally, I like to imagine a lasso pulling numbers down to zero on a number line. This reminds me that lasso regression can cause some of the model’s coefficients to be zero. Since the L1 norm creates the constraint region that makes this possible, we know that Lasso uses the L1 norm as its penalty term. If you remember that lasso and ridge use the L1 and L2 norms as penalty terms, it follows that ridge uses the L2 norm.</p><p name="fc78" id="fc78" class="graf graf--p graf-after--p">Hopefully this can help someone having a hard time keeping these two regression methods straight.</p><p name="c37f" id="c37f" class="graf graf--p graf--empty graf-after--p graf--trailing"><br></p></div></div></section>
</section>
</article>
    </div>

    <footer>
        <div class="tags">
            <a href="./tag/regularization.html">regularization</a>
            <a href="./tag/lasso.html">lasso</a>
            <a href="./tag/ridge.html">ridge</a>
        </div>
        <div class="pure-g post-footer">
            <div class="pure-u-1 pure-u-md-1-2">
                <div class="pure-g poster-info">
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="./author/alex-harlan.html">Alex Harlan</a></h3>
                        <p class="author-description">
                        </p>
                    </div>
                </div>
            </div>



        </div>


    </footer>


</div>


</body>
</html>